<!DOCTYPE html>
<html lang="en">
<head>
    <title>
        ThRaSH Seminars
    </title>
    <!-- Next line is for the nice mobile view -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../../thrash.css">
</head>
<body>

    <nav class="nav-container">
        <div class="nav-menu">
            <ul class="menu-list">
                <li class="menu-item"><a href="https://thrash-seminars.github.io/pre/">Previous</a></li>
                <li class="menu-item"><a href="https://thrash-seminars.github.io/">Home</a></li>
            </ul>
        </div>
    </nav>

    <div class="main">
         <h1>ThRaSH Seminars Series</h1>
<h2 id="about">About ThRaSH</h2>
        <p>Randomized search heuristics such as stochastic gradient methods, simulated annealing, evolutionary algorithms, stochastic neural networks for optimization, ant colony and swarm optimization, and the cross-entropy method are frequently used across many scientific communities. They have been successfully applied in various domains, both for combinatorial and numerical optimization. Despite their success in practice, proving that such algorithms satisfy certain performance guarantees is still a difficult and widely open problem.</p>
        <p>The mission of the theory of randomized search heuristics (ThRaSH) seminar series is to contribute to the theoretical understanding of randomized search heuristics, in particular of their computational complexity. The aim is to stimulate interactions within the research field and between people from different disciplines working on randomized algorithms. The primary focus is on discussing recent ideas and detecting challenging topics for future work, rather than on the presentation of final results.</p>
        <p>Steering Committee (Alphabetic order)</p>
        <ul>
        <li><a href="http://www.lix.polytechnique.fr/Labo/Benjamin.Doerr/">Benjamin Doerr</a> (Ã‰cole Polytechnique, France)</li>
        <li><a href="https://users.aber.ac.uk/thj10/">Thomas Jansen</a> (Aberystwyth University, UK)</li>
        <li><a href="https://hpi.de/friedrich/people/timo-koetzing.html">Timo K&ouml;tzing</a> (Hasso Plattner Institute Potsdam, Germany)</li>
        <li><a href="https://www.cs.bham.ac.uk/~lehrepk/">Per Kristian Lehre</a> (University of Birmingham, UK)</li>
        <li><a href="https://www.sustech.edu.cn/en/faculties/pietrooliveto.html">Pietro S. Oliveto</a> (Southern University of Science and Technology, China)</li>
        <li><a href="https://www.imm.dtu.dk/~cawi/">Carsten Witt</a> (Technical University of Denmark)</li>
        </ul>
        
        <h2>Talks in Autumn/Winter 2024</h2>

        <p><b>When?</b> On Tuesday at 15:00 CE(S)T. This is UTC 13:00 before 29-th October and UTC 13:00 after that. 

        <p><b>Where?</b> Here is a <a href="https://dtudk.zoom.us/j/65818691920?pwd=cGY1aWsraXZXUHRtVEpJc3Vicy92dz09">permanent zoom link</a>.</p>

        <p><b>Mailing list?</b> Subscribe to the seminar mailing list <a href="https://www.jiscmail.ac.uk/cgi-bin/wa-jisc.exe?A0=THRASH-SEMINARS" target="_blank">here</a>. If you want to get all the ThRaSH-related news, subscribe to <a href="https://www.jiscmail.ac.uk/cgi-bin/wa-jisc.exe?A0=THRASH" target="_blank">this list</a> as well.</p>

        <p><b>Organizers:</b> <a href="https://www.fim.uni-passau.de/en/intelligent-systems/team/research-staff/">Andre Opris</a> and <a href="https://www.cs.bham.ac.uk/~lehrepk/">Per Kristian Lehre</a>.</p>

        <h3 id="Schedule">Schedule</h3>

        <!--<p>All seminars will be added to <a href="https://calendar.google.com/calendar/embed?src=00ae99cd98c6cb6e82b2594b37d22900dd8f8c441a587bb45bb87be550a6c8c7%40group.calendar.google.com" target="_blank">this google calendar</a> (the times are displayed in CE(S)T). To subscribe to this calendar, <a href="https://calendar.google.com/calendar/u/0?cid=MDBhZTk5Y2Q5OGM2Y2I2ZTgyYjI1OTRiMzdkMjI5MDBkZDhmOGM0NDFhNTg3YmI0NWJiODdiZTU1MGE2YzhjN0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t" target="_blank">use this link</a>.</p>-->

        <ul>
            <li><a href="#Oct22"><b>22 October: </b>Shengjie Ren, <i>A First Running Time Analysis of the Strength Pareto Evolutionary Algorithm 2 (SPEA2) </i></a></li>
            <li><a href="#Oct29"><b>29 October: </b>Alistair Benford, <i>Runtime analysis of coevolutionary algorithms on a class of symmetric zero-sum games </i></a></li>
            <li><a href="#Nov5"><b>5 November: </b>Jon Rowe, <i>Finding the hidden subset in hidden subset problems </i></a></li>
        </ul>

        <h3>Abstracts of the talks</h3>

        <dl id="Oct22">
            <dt><strong>22 October 2024</strong></dt>
                
            <dd>
                <p><i>First Running Time Analysis of the Strength Pareto Evolutionary Algorithm 2 (SPEA2) </i> &mdash; <a href="https://www.lamda.nju.edu.cn/qianc/">Shengjie Ren</a>, School of Artificial Intelligence, Nanjing University, China</p>

                <p>
                    Evolutionary algorithms (EAs) have emerged as a predominant approach for addressing multi-objective optimization problems. However, the theoretical foundation of 
                    multi-objective EAs (MOEAs), particularly the fundamental aspects like running time analysis, remains largely underexplored. Existing theoretical studies mainly 
                    focus on basic MOEAs, with little attention given to practical MOEAs. Recently, researchers have begun to examine practical MOEAs, 
                    e.g., NSGA-II/III, MOEA/D, and SMS-EMOA. However, the running time analysis of Strength Pareto Evolutionary Algorithm 2 (SPEA2), one of the most popular MOEAs, has not been touched.

                    In this talk, we will present the first theoretical analysis of the running time for SPEA2 on three commonly studied multi-objective optimization problems: $m$OneMinMax, $m$LeadingOnesTrailingZeroes, 
                    and $m$-OneJumpZeroJump. We show that SPEA2 achieves expected running times of $O(\mu n\cdot \min{m\log n, n})$, $O(\mu n^2)$, and $O(\mu n^k \cdot \min{mn, 3^{m/2}})$ for these 
                    problems respectively, where $m$ is the number of objectives, and $\mu$ is the population size. The proofs are accomplished through general theorems which are also applicable for analyzing the expected 
                    running time of other MOEAs on these problems, and thus can be helpful for future theoretical analysis of MOEAs.
                    
                </p>
            </dd>
            <dl id="Oct29">
            <dt><strong>29 October 2024</strong></dt>

            <dd>
                <p><i>Population Diversity in Fitness-Neutral Landscapes </i>&mdash; <a href="https://inf.ethz.ch/people/people-atoz/person-detail.MTc0MDI5.TGlzdC8zMDQsLTIxNDE4MTU0NjA=.html">Johannes Lengler</a>, ETH Zurich, Switzerland</p>
                <p>
                    One one the major advantages of population-based optimization heuristics
    like genetic algorithms is that we can recombine two or more solutions into
    a new one by crossover. In practice, crossover is known
    to be extremely helpful, and we would also like to understand how much it
    helps in theoretical benchmarks. However, there is one obstacle: The
    effectiveness of crossover depends on the population diversity (e.g.,
    measured by average Hamming distance of the solutions), so we need to
    understand how the diversity of a population evolves over time.</p>

    <p>    We answer this question under a seemingly very strong assumption: for a
    flat objective function, i.e., in absence of fitness signals. We show that
    in this case, surprisingly, the details of algorithm have almost no
    influence on the diversity. Specifically, for the (&mu;+1) Genetic Algorithm
    we show that diversity approaches an equilibrium which (almost) does not
    depend on the used mutation or crossover operators. The equilibrium point
    increases linearly with the population size.
</p>
                <p>
    Although flat objective functions are seemingly uninteresting, the result
    turned out to be surprisingly useful. I will give one application: for
    Jump, a standard benchmark for local optima, the runtime of the (&mu;+1) GA
    with a small modification is reduced massively by crossover, because the
    natural diversity in this range is large enough to speed up optimization.
    </p>
                
            </dd>
 </dl>

    </div>
</body>
